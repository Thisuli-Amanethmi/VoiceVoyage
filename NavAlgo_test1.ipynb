{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPzyxKNw7Up3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Placeholder function for object detection\n",
        "def perform_object_detection(frame):\n",
        "    #  object detection code\n",
        "    # This function should return the position (x, y) of the detected object\n",
        "    # For simplicity, assume the position is (100, 200) for now\n",
        "    return (100, 200)\n",
        "\n",
        "# Placeholder function for mapping object position to RDF map\n",
        "def map_object_position_to_rdf(object_position):\n",
        "    #  mapping code\n",
        "    # This function should map the position of the detected object to the RDF map\n",
        "    # For simplicity, assume a predefined mapping for demonstration\n",
        "    rdf_map = {\n",
        "        (100, 200): \"Kitchen\",\n",
        "        (300, 400): \"Living Room\",\n",
        "        # Add more mappings as needed\n",
        "    }\n",
        "    return rdf_map.get(object_position, \"Unknown\")\n",
        "\n",
        "# Initialize the camera (or use a video stream)\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Perform object detection to get the position of the detected object\n",
        "    object_position = perform_object_detection(frame)\n",
        "\n",
        "    # Map the position of the detected object to the RDF map\n",
        "    location = map_object_position_to_rdf(object_position)\n",
        "\n",
        "    # Assuming the position of the blind person based on the detected object\n",
        "    if location != \"Unknown\":\n",
        "        print(\"Assuming the blind person is in the\", location)\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow('Frame', frame)\n",
        "\n",
        "    # Check for 'q' key press to exit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to preprocess user input and validate against predefined objects\n",
        "def preprocess_input(user_input):\n",
        "    predefined_objects = {\n",
        "        \"window\", \"chair\", \"sink\", \"pantry-cupboards\", \"wall-art\", \"washing-machine\",\n",
        "        \"bookshelf\", \"clothes-rack\", \"commode\", \"lamp\", \"cupboard\", \"sofa\", \"oven\",\n",
        "        \"refrigerator\", \"stove\", \"door\", \"coffee-table\", \"bed\", \"tv\", \"staircase\",\n",
        "        \"table\", \"dressing-table\", \"shoe-rack\"\n",
        "    }\n",
        "    # Normalize input: remove leading/trailing spaces, convert to lowercase, and remove hyphens\n",
        "    normalized_input = user_input.strip().lower().replace(\"-\", \"\")\n",
        "    # Check if normalized input matches any predefined object\n",
        "    for obj in predefined_objects:\n",
        "        if normalized_input == obj.replace(\"-\", \"\"):\n",
        "            return obj\n",
        "    # If not matched, split input by space, remove hyphens, and concatenate words\n",
        "    normalized_input = \"\".join(user_input.strip().lower().split())\n",
        "    for obj in predefined_objects:\n",
        "        if normalized_input == obj.replace(\"-\", \"\"):\n",
        "            return obj\n",
        "    return None\n",
        "\n",
        "# Function to validate object inputs\n",
        "def validate_object_input(prompt):\n",
        "    while True:\n",
        "        user_input = input(prompt).strip().lower()\n",
        "        preprocessed_input = preprocess_input(user_input)\n",
        "        if preprocessed_input:\n",
        "            return preprocessed_input\n",
        "        else:\n",
        "            print(\"Object not recognized. Please try again.\")\n",
        "\n",
        "# Function to validate yes/no inputs\n",
        "def validate_yes_no_input(prompt):\n",
        "    while True:\n",
        "        user_input = input(prompt).strip().lower()\n",
        "        if user_input in {'yes', 'no'}:\n",
        "            return user_input\n",
        "        else:\n",
        "            print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
        "\n",
        "# Initialize variables to store user inputs\n",
        "print(\"Please enter objects from the given list only.\")\n",
        "print(\"(window, chair, sink, pantry-cupboards, wall-art, washing-machine, bookshelf, clothes-rack, commode, lamp, cupboard, sofa, oven, refrigerator, stove, door, coffee-table, bed, tv, staircase, table, dressing-table, shoe-rack)\")\n",
        "in_front = validate_object_input(\"In Front: Directly in front of you as you enter, you see \")\n",
        "to_the_left = validate_object_input(\"To the Left: The first object to your immediate left is \")\n",
        "far_left = validate_object_input(\"In the far left corner or section, you can find \")\n",
        "to_the_right = validate_object_input(\"To the Right: On your immediate right, there is \")\n",
        "far_right = validate_object_input(\"Further to the far right, the area is occupied by \")\n",
        "behind_you = validate_object_input(\"Behind You: Turning around, the space behind you includes \")\n",
        "\n",
        "# Assuming the position of the blind person based on the detected objects\n",
        "def assume_person_position(objects):\n",
        "    # Define mapping of objects to relative positions\n",
        "    object_mapping = {\n",
        "        'left': [to_the_left, far_left],\n",
        "        'right': [to_the_right, far_right],\n",
        "        'front': [in_front],\n",
        "        'behind': [behind_you]\n",
        "    }\n",
        "\n",
        "    # Compare the detected objects with the predefined positions\n",
        "    for position, objects_at_position in object_mapping.items():\n",
        "        if all(obj in objects for obj in objects_at_position):\n",
        "            return f\"The person is assumed to be {position}.\"\n",
        "\n",
        "    return \"The person's position could not be determined.\"\n",
        "\n",
        "# Object detection function (placeholder)\n",
        "def perform_object_detection(frame):\n",
        "    # Placeholder code for object detection\n",
        "    #  object detection code\n",
        "    # For demonstration purposes,  assume object positions\n",
        "    return [\"sink\", \"chair\", \"table\"]\n",
        "\n",
        "# Initialize the camera (or use a video stream)\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Perform object detection to get the detected objects\n",
        "    detected_objects = perform_object_detection(frame)\n",
        "\n",
        "    # Assuming the position of the person based on the detected objects\n",
        "    person_position = assume_person_position(detected_objects)\n",
        "    print(person_position)\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow('Frame', frame)\n",
        "\n",
        "    # Check for 'q' key press to exit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "3svVR8vG9pG2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}